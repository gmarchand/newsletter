{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5660fe27-27f4-4421-bad1-b7108479b4fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Newsletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e094190e-d137-4ad6-a4a6-affdf2636a79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker 2.203.0 requires uvicorn==0.22.0, but you have uvicorn 0.23.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --requirement requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84edc707-c5a5-484d-8d88-1e838b86ab92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "from typing import Any, Dict\n",
    "import boto3\n",
    "import html2text\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "from langchain.globals import set_debug\n",
    "set_verbose(False)\n",
    "set_debug(False)\n",
    "\n",
    "# OPENAI Keys\n",
    "# OPENAI_API_KEY=xxx\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b102f-8118-4311-a9f1-e699421c1f02",
   "metadata": {},
   "source": [
    "## Import Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "760db1c9-6e92-406f-b8a7-b7fbf2ee9dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 17:41:31.343 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/1-d9zHiwDtVUvP9v7ZW3O2Ys6f24Yz_W8zKaNb5uy8dY/edit#gid=0\"\n",
    "# Create a connection object.\n",
    "conn = st.connection(\"gsheets\", type=GSheetsConnection)\n",
    "df = conn.read(spreadsheet=url, worksheet=\"0\", ttl=\"24h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bacb7-522e-4f01-a38f-17dd9c84b9f6",
   "metadata": {},
   "source": [
    "### Clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d545211-1f34-476e-b2cf-67597796cba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def html_to_text(text):\n",
    "    text = \"\" if isinstance(text,float) else text\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = True\n",
    "    return h.handle(text)\n",
    "\n",
    "df['ArticleContentTxt'] = df['ArticleContent'].apply(html_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb256804-f60e-411e-94fb-81468e02e421",
   "metadata": {},
   "source": [
    "## French title and summary of each blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32162eb3-f612-4983-9cd7-1877f5c28b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4c25788-5d15-4207-bcac-4bba0a783c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelId = \"anthropic.claude-v2:1\"\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "model = Bedrock(\n",
    "    model_id=modelId,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 4096,\n",
    "        \"stop_sequences\": [],\n",
    "        \"temperature\": 0.5,  # Use a lower value to decrease randomness in the response.\n",
    "        \"top_p\": 1,  # Use a lower value to ignore less probable options.\n",
    "        \"top_k\": 250,  # Specify the number of token choices the model uses to generate the next token.\n",
    "    },\n",
    "    client=bedrock_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76f21da5-56d0-4a42-bdf7-3cf940b12ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_df_columns_to_list_dicts(dataframe: pd.DataFrame, column_names: List[str]) -> List[dict]:\n",
    "    result = []\n",
    "    for row in dataframe.itertuples():\n",
    "        dictionary = {}\n",
    "        for column_name in column_names:\n",
    "            dictionary[column_name] = getattr(row, column_name)\n",
    "        result.append(dictionary)\n",
    "    return result\n",
    "\n",
    "def transform_list_of_dicts_to_dataframe(dicts):\n",
    "   \n",
    "    # Create an empty DataFrame with appropriate column names\n",
    "    column_names = set(key for dictionary in dicts for key in dictionary.keys())\n",
    "    df_tmp = pd.DataFrame(columns=list(column_names))\n",
    "\n",
    "    # Transform dictionaries to the DataFrame\n",
    "    for dictionary in dicts:\n",
    "        df_tmp = df_tmp._append(dictionary,ignore_index=True)        \n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "new_dicts = transform_df_columns_to_list_dicts(df, ['ArticleTitle', 'ArticleURL'])\n",
    "new_df = transform_list_of_dicts_to_dataframe(new_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5af1c-8612-403a-ac7c-427c5ada948b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With PyDantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b12b53d-eab8-4aac-9120-8ea77bb7b9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RssItemTitles(ArticleTitle='Amazon Titan Image Generator Demo - Image Playground | Amazon Web Services', ArticleTitleFrench=\"Démonstration du générateur d'images Titan d'Amazon - terrain de jeu d'images | Amazon Web Services\", ArticleSummaryFrench=\"Le générateur d'images Titan d'Amazon permet aux créateurs de contenu une idéation et une itération rapides résultant en une génération d'images à haute efficacité.\"),\n",
       " RssItemTitles(ArticleTitle='Amazon ECS and AWS Fargate now integrate with Amazon EBS', ArticleTitleFrench='Amazon ECS et AWS Fargate sont désormais intégrés avec Amazon EBS', ArticleSummaryFrench=\"Amazon ECS et AWS Fargate permettent maintenant de provisionner et attacher facilement des volumes EBS aux tâches Amazon ECS s'exécutant sur Fargate et EC2 à l'aide des API Amazon ECS.\"),\n",
       " RssItemTitles(ArticleTitle='Effective data sorting with Amazon DynamoDB', ArticleTitleFrench='Un tri efficace des données avec Amazon DynamoDB', ArticleSummaryFrench='Comment trier efficacement les données stockées dans Amazon DynamoDB'),\n",
       " RssItemTitles(ArticleTitle='AWS re:Invent 2023 - Creating an interactive AI Twitch streamer on AWS (COM209)', ArticleTitleFrench=\"AWS re:Invent 2023 - Création d'un streamer Twitch IA interactif sur AWS (COM209)\", ArticleSummaryFrench=\"Cette discussion explore la construction sur AWS d'un streamer Twitch doté d'une IA capable d'interactions humaines en utilisant Amazon Bedrock, Python et l'API Twitch.\"),\n",
       " RssItemTitles(ArticleTitle='Automating CloudFront Continuous Deployment with a CI/CD Pipeline', ArticleTitleFrench='Automatisation du déploiement continu de CloudFront avec un pipeline CI/CD', ArticleSummaryFrench=\"Cet article explique comment automatiser le déploiement continu de CloudFront à l'aide d'un pipeline d'intégration et de livraison continues.\"),\n",
       " RssItemTitles(ArticleTitle='How to leverage Application Load Balancer’s advanced request routing to route application traffic across multiple Amazon EKS clusters', ArticleTitleFrench=\"Comment tirer parti du routage de requêtes avancé d'Application Load Balancer pour router le trafic d'applications sur plusieurs clusters Amazon EKS\", ArticleSummaryFrench=\"Cet article explique comment utiliser les fonctionnalités de routage de requêtes avancées d'Application Load Balancer pour router le trafic vers des microservices répartis sur plusieurs clusters Amazon EKS dans une région AWS donnée.\"),\n",
       " RssItemTitles(ArticleTitle='How Wonder Dynamics is accelerating creativity with AWS', ArticleTitleFrench='Comment Wonder Dynamics accélère la créativité avec AWS', ArticleSummaryFrench=\"Wonder Dynamics utilise l'IA et le cloud AWS pour rendre la création d'effets visuels plus accessible et abordable, permettant ainsi à plus de voix créatives d'être entendues.\"),\n",
       " RssItemTitles(ArticleTitle='Host the Whisper Model on Amazon SageMaker: exploring inference options', ArticleTitleFrench=\"Héberger le modèle Whisper sur Amazon SageMaker : explorer les options d'inférence\", ArticleSummaryFrench=\"Cet article explore les options d'inférence du modèle de reconnaissance vocale Whisper sur Amazon SageMaker, y compris les points de terminaison en temps réel, les travaux de transformation par lots et les points de terminaison d'inférence asynchrones.\"),\n",
       " RssItemTitles(ArticleTitle='Amazon EKS extended support for Kubernetes versions pricing', ArticleTitleFrench=\"Tarification du support étendu pour les versions de Kubernetes d'Amazon EKS\", ArticleSummaryFrench='Amazon EKS a annoncé la tarification pour le support étendu des versions de Kubernetes, qui sera de 0,60 $ par cluster et par heure.'),\n",
       " RssItemTitles(ArticleTitle='OpenSearch Expands Leadership Beyond AWS', ArticleTitleFrench=\"OpenSearch étend son leadership au-delà d'AWS\", ArticleSummaryFrench=\"OpenSearch a lancé son premier comité de direction en décembre 2023, une étape importante vers une gouvernance ouverte au-delà d'AWS.\"),\n",
       " RssItemTitles(ArticleTitle='Unlocking cloud-based quality of experience (QoE) management with TAG and AWS', ArticleTitleFrench=\"Déverrouiller la gestion de la qualité de l'expérience (QoE) basée sur le cloud avec TAG et AWS\", ArticleSummaryFrench=\"L'intégration de la plateforme TAG Realtime Media avec l'infrastructure AWS présente une approche techniquement avancée pour la surveillance et la gestion de la diffusion.\"),\n",
       " RssItemTitles(ArticleTitle='Power neural search with AI/ML connectors in Amazon OpenSearch Service', ArticleTitleFrench='Améliorez la recherche neuronale avec les connecteurs IA / ML dans Amazon OpenSearch Service', ArticleSummaryFrench='Cet article explique comment configurer des connecteurs IA/ML vers des modèles externes via la console Amazon OpenSearch Service pour alimenter la recherche sémantique.'),\n",
       " RssItemTitles(ArticleTitle='Better understand sports fan data with Fan360 on AWS', ArticleTitleFrench='Mieux comprendre les données des fans de sport avec Fan360 sur AWS', ArticleSummaryFrench=\"Les entités sportives peuvent gérer les données de fans disponibles en tant que sources entrantes du domaine de données Fan360, et créer des produits de données Fan360 raffinés pour les exposer à d'autres équipes internes, ou à des tiers en fonction du cas d'utilisation.\"),\n",
       " RssItemTitles(ArticleTitle='Create Fan360 data products on AWS', ArticleTitleFrench='Créer des produits de données Fan360 sur AWS', ArticleSummaryFrench=\"En combinant les données de différentes sources, les entités sportives peuvent construire un domaine de données Fan360 avec des produits de données raffinés, à enrichir et à partager dans toute l'organisation, avec les partenaires et les sponsors.\"),\n",
       " RssItemTitles(ArticleTitle='adidas: Building a streaming analytics application with AWS Analytics | AWS Events', ArticleTitleFrench=\"adidas: Construction d'une application d'analyse de streaming avec AWS Analytics | Événements AWS\", ArticleSummaryFrench=\"Paul Vassu, vice-président de l'ingénierie de plateforme chez adidas, explique comment adidas a construit une application d'analyse de streaming qui aide à changer des vies grâce au sport.\"),\n",
       " RssItemTitles(ArticleTitle='The journey to IPv6 on Amazon EKS: Interoperability scenarios (Part 3)', ArticleTitleFrench=\"Le voyage vers IPv6 sur Amazon EKS : scénarios d'interopérabilité (Partie 3)\", ArticleSummaryFrench=\"Cet article explique comment les clusters Amazon EKS en espace d'adressage IPv6 interagissent et interopèrent avec les réseaux IPv4 ainsi que les services AWS.\"),\n",
       " RssItemTitles(ArticleTitle='Announcing the Amazon Titan Multimodal Embeddings model in Amazon Bedrock | AWS Events', ArticleTitleFrench='Annonce du modèle Amazon Titan Multimodal Embeddings dans Amazon Bedrock | AWS Events', ArticleSummaryFrench='Amazon Titan Multimodal Embeddings aide les clients à alimenter des expériences de recherche, de recommandation et de personnalisation multimodales plus précises et contextuellement pertinentes pour les utilisateurs finaux.'),\n",
       " RssItemTitles(ArticleTitle='RED Camera Cloud Upload to AWS', ArticleTitleFrench='Téléchargement dans le cloud de la caméra RED vers AWS', ArticleSummaryFrench='En 2023, RED Digital Cinema a introduit le téléchargement dans le cloud, la capacité de télécharger directement vers Amazon Simple Storage Service (Amazon S3) à partir de ses caméras cinématographiques (séries RED Raptor et RED Komodo).'),\n",
       " RssItemTitles(ArticleTitle='Amazon EKS and Amazon EKS Distro now support Kubernetes version 1.29', ArticleTitleFrench='Amazon EKS et Amazon EKS Distro prennent désormais en charge la version 1.29 de Kubernetes', ArticleSummaryFrench=\"La version 1.29 de Kubernetes a introduit plusieurs nouvelles fonctionnalités et corrections de bugs, et AWS est heureux d'annoncer que vous pouvez désormais utiliser Amazon EKS et Amazon EKS Distro pour exécuter la version 1.29 de Kubernetes.\"),\n",
       " RssItemTitles(ArticleTitle='Ateliere and AWS sign SCA for 5 years collaboration', ArticleTitleFrench='Ateliere et AWS signent un ACC pour 5 ans de collaboration', ArticleSummaryFrench=\"Ateliere Creative Technologies, développeur de solutions natives pour le cloud pour la chaîne d'approvisionnement médiatique, a conclu un accord de collaboration stratégique de 5 ans avec Amazon Web Services pour introduire des solutions basées sur le cloud qui couvrent la production et la distribution de médias.\"),\n",
       " RssItemTitles(ArticleTitle='Behind the scenes: AWS real-time architecture for Bundesliga Match Facts', ArticleTitleFrench=\"Dans les coulisses : l'architecture en temps réel d'AWS pour les faits de match de la Bundesliga\", ArticleSummaryFrench=\"Cet article explique comment l'architecture sans serveur basée sur les événements d'AWS permet de fournir des statistiques de match de football en temps réel à 500 millions de fans dans le monde.\")]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data structure\n",
    "class RssItemTitles(BaseModel):\n",
    "    ArticleTitle: str = Field(description=\"Title of the article\")\n",
    "    ArticleTitleFrench: str = Field(description=\"Title of the article translated in French\")\n",
    "    #ArticleContentTxt: str = Field(description=\"Content of the article\")\n",
    "    ArticleSummaryFrench: str = Field(description=\"Summary of content of the article translated in French\")\n",
    "    \n",
    "        \n",
    "\n",
    "translate_template = \"\"\"\n",
    "You will be acting as a Solutions Architect, working for Amazon Web Services. You are a specialist of Cloud Computing technologies and AWS. You write articles on AWS Blog post. \n",
    "\n",
    "First, translate in French, the title of this article.\n",
    "Secondly, create an engaging summary of one sentence in french based of the content of this article.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "<title>\n",
    "{ArticleTitle}\n",
    "</title>\n",
    "\n",
    "<content>\n",
    "{ArticleContentTxt}\n",
    "</content>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=RssItemTitles)\n",
    "prompt_translate = PromptTemplate.from_template(\n",
    "    template=translate_template,\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "chain = prompt_translate | model | parser\n",
    "#chain.invoke({\"ArticleTitle\":\"Automating CloudFront Continuous Deployment with a CI/CD Pipeline\", \"ArticleContentTxt\":\"In November 2022, Amazon Web Services (AWS) announced the launch of Amazon CloudFront continuous deployment, extending the functionality of your existing CloudFront distributions by allowing you to test and validate configuration changes to a percentage of live traffic before extending to your wider audience. Previously, customers had to do the heavy lifting of changing DNS records and creating separate domains for testing to then override DNS settings on clients for utilizing that endpoint once ready for production. Additionally, changes on lower environments need a hard change to production which can negatively affect production traffic. These efforts create inconsistencies, headaches, and significant overhead between environments that are hard to manage and maintain.\"})\n",
    "results = chain.batch(transform_df_columns_to_list_dicts(df, ['ArticleTitle','ArticleContentTxt']))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0926a-6c3a-4d09-a2d9-c4a2c96d877b",
   "metadata": {},
   "source": [
    "### With DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c6acfc9-f5ab-475d-a803-3464d220d4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"First step: for each row of the dataframe.\\n Second step: get the text of the column ArticleContentTxt.\\n Third step: Summarize this text.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"First step: for each row of the dataframe.\\n Second step: get the text of the column ArticleContentTxt.\\n Third step: Summarize this text.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"base\",\n",
      "    \"StringPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"text\": \"\\nYou will be acting as a Solutions Architect, working for Amazon Web Services. you are a specialist of Cloud technologies and AWS.\\n\\nThe output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\\n1. The column names are limited to the possible columns below.\\n2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\\n3. Remember that arrays are optional and not necessarily required.\\n4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \\\"Invalid column\\\" or \\\"Invalid operation\\\".\\n\\nAs an example, for the formats:\\n1. String \\\"column:num_legs\\\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\\n2. String \\\"row:1\\\" is a well-formatted instance which gets row 1.\\n3. String \\\"column:num_legs[1,2]\\\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\\n4. String \\\"row:1[num_legs]\\\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\\n5. String \\\"mean:num_legs[1..3]\\\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\\n6. String \\\"do_something:num_legs\\\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\\n7. String \\\"mean:invalid_col\\\" is a badly-formatted instance, where invalid_col is not a possible column.\\n\\nHere are the possible columns:\\n```\\nCreatedAt, ArticlePublishedAt, ArticleTitle, ArticleContent, ArticleURL, ArticleCategories, SourceTitle, SourceURL, Content, Summary, ArticleContentTxt\\n```\\n\\n\\nFirst step: for each row of the dataframe.\\n Second step: get the text of the column ArticleContentTxt.\\n Third step: Summarize this text.\\n\\n\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nYou will be acting as a Solutions Architect, working for Amazon Web Services. you are a specialist of Cloud technologies and AWS.\\n\\nThe output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\\n1. The column names are limited to the possible columns below.\\n2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\\n3. Remember that arrays are optional and not necessarily required.\\n4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \\\"Invalid column\\\" or \\\"Invalid operation\\\".\\n\\nAs an example, for the formats:\\n1. String \\\"column:num_legs\\\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\\n2. String \\\"row:1\\\" is a well-formatted instance which gets row 1.\\n3. String \\\"column:num_legs[1,2]\\\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\\n4. String \\\"row:1[num_legs]\\\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\\n5. String \\\"mean:num_legs[1..3]\\\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\\n6. String \\\"do_something:num_legs\\\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\\n7. String \\\"mean:invalid_col\\\" is a badly-formatted instance, where invalid_col is not a possible column.\\n\\nHere are the possible columns:\\n```\\nCreatedAt, ArticlePublishedAt, ArticleTitle, ArticleContent, ArticleURL, ArticleCategories, SourceTitle, SourceURL, Content, Summary, ArticleContentTxt\\n```\\n\\n\\nFirst step: for each row of the dataframe.\\n Second step: get the text of the column ArticleContentTxt.\\n Third step: Summarize this text.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [995ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Invalid operation: do_something\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Invalid operation: do_something\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 6,\n",
      "      \"prompt_tokens\": 497,\n",
      "      \"total_tokens\": 503\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:PandasDataFrameOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:PandasDataFrameOutputParser] [2ms] Parser run errored with error:\n",
      "\u001b[0m\"OutputParserException('Invalid operation: do_something. Please check the format instructions.')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 1246, in _call_with_config\\n    context.run(\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/config.py\\\", line 326, in call_func_with_variable_args\\n    return func(input, **kwargs)  # type: ignore[call-arg]\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py\\\", line 168, in <lambda>\\n    lambda inner_input: self.parse_result(\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py\\\", line 219, in parse_result\\n    return self.parse(result[0].text)\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/output_parsers/pandas_dataframe.py\\\", line 92, in parse\\n    raise OutputParserException(\\n\\n\\nlangchain_core.exceptions.OutputParserException: Invalid operation: do_something. Please check the format instructions.\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [1.01s] Chain run errored with error:\n",
      "\u001b[0m\"OutputParserException('Invalid operation: do_something. Please check the format instructions.')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 2053, in invoke\\n    input = step.invoke(\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py\\\", line 167, in invoke\\n    return self._call_with_config(\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 1246, in _call_with_config\\n    context.run(\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/config.py\\\", line 326, in call_func_with_variable_args\\n    return func(input, **kwargs)  # type: ignore[call-arg]\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py\\\", line 168, in <lambda>\\n    lambda inner_input: self.parse_result(\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py\\\", line 219, in parse_result\\n    return self.parse(result[0].text)\\n\\n\\n  File \\\"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/output_parsers/pandas_dataframe.py\\\", line 92, in parse\\n    raise OutputParserException(\\n\\n\\nlangchain_core.exceptions.OutputParserException: Invalid operation: do_something. Please check the format instructions.\"\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Invalid operation: do_something. Please check the format instructions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#df_query = \"translate in French, the content of each line of the column ArticleTitle.\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst step: for each row of the dataframe.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Second step: get the text of the column ArticleContentTxt.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Third step: Summarize this text.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m parser_output \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_query\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m parser_output\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:167\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    179\u001b[0m             config,\n\u001b[1;32m    180\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:1246\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1243\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1244\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1245\u001b[0m         Output,\n\u001b[0;32m-> 1246\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1254\u001b[0m     )\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:168\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    165\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 168\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    172\u001b[0m             config,\n\u001b[1;32m    173\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    179\u001b[0m             config,\n\u001b[1;32m    180\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:219\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/output_parsers/pandas_dataframe.py:92\u001b[0m, in \u001b[0;36mPandasDataFrameOutputParser.parse\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     90\u001b[0m request_type, request_params \u001b[38;5;241m=\u001b[39m splitted_request\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_type \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid column\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid operation\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please check the format instructions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[1;32m     95\u001b[0m array_exists \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[.*?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m, request_params)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m array_exists:\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Invalid operation: do_something. Please check the format instructions."
     ]
    }
   ],
   "source": [
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "df_template = \"\"\"\n",
    "You will be acting as a Solutions Architect, working for Amazon Web Services. you are a specialist of Cloud technologies and AWS.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "{query}\n",
    "\n",
    "\"\"\"\n",
    "# Set up the prompt.\n",
    "prompt = PromptTemplate(\n",
    "    template=df_template,\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "#df_query = \"translate in French, the content of each line of the column ArticleTitle.\"\n",
    "df_query = \"First step: for each row of the dataframe.\\n Second step: get the text of the column ArticleContentTxt.\\n\"\n",
    "parser_output = chain.invoke({\"query\": df_query })\n",
    "parser_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30749dad-6b19-401f-a188-885483ea44a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
